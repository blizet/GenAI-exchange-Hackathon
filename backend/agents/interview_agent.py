# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""This agent has been refactored to be compatible with the installed google-adk library.
The original implementation used an `@agent.impl` decorator that is not supported by the
LlmAgent class in the current library version. The logic has been moved into a subclass
of LlmAgent, overriding the `_run_async_impl` method, which is the correct pattern for
implementing custom, stateful agent logic with this library.
"""

from google.adk.agents.llm_agent import LlmAgent
from google.adk.agents.invocation_context import InvocationContext
from google.adk.events.event import Event
from google.genai.types import Content, Part

from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any, AsyncGenerator
import datetime
from langchain_google_genai import ChatGoogleGenerativeAI

# --- Pydantic Models for State and Output ---

class InterviewState(BaseModel):
    """Manages the state of a single investor-founder interview session."""
    interview_started: bool = Field(default=False, description="True if the interview has begun.")
    current_question_index: int = Field(default=0, description="Index of the current primary question.")
    total_questions: int = Field(default=0, description="Total number of primary questions.")
    questions_list: List[str] = Field(default=[], description="The full, ordered list of primary questions.")
    answers_collected: List[Dict[str, Any]] = Field(default=[], description="Log of questions asked and answers received.")
    followup_count_for_current: int = Field(default=0, description="Number of follow-ups asked for the current primary question.")
    max_followups_per_question: int = Field(default=3, description="Maximum follow-up questions allowed per primary question.")
    interview_complete: bool = Field(default=False, description="True if all questions have been answered.")
    followups_asked: List[str] = Field(default=[], description="A list of follow-up questions already asked for the current primary question to avoid repetition.")
    startup_context: str = Field(default="", description="The initial context document about the startup.")
    full_history: List[Dict[str, str]] = Field(default=[], description="Full conversation history")
    last_question_asked_by_bot: str = Field(default="", description="The exact text of the last question (primary or follow-up) asked by the bot.")

class InterviewerOutput(BaseModel):
    """The structured output from the Interviewer Agent."""
    response_text: str = Field(description="The text to be spoken to the user (e.g., a question, a transition, or a closing statement).")
    is_followup_question: bool = Field(description="True if this is a follow-up question based on the user's last answer.")
    is_primary_question: bool = Field(description="True if this is the next primary question from the initial list.")
    is_closing_statement: bool = Field(description="True if the interview is over and this is a concluding remark.")
    confidence_in_answer_coverage: float = Field(
        description="A score from 0.0 to 1.0 indicating how well the user's last answer addressed the question. 1.0 means fully addressed."
    )

# --- Agent Instruction ---

investor_interview_instruction = f"""
You are VentureMind AI, a sophisticated interviewing agent for a venture capital firm. Your role is to conduct a structured but adaptive interview with startup founders. You are firm, insightful, and always focused on getting to the heart of the matter.

**YOUR CONTEXT:**
- You have been provided with a confidential analysis of the startup.
- You have a pre-approved list of primary questions generated by your analyst team.
- Your goal is to work through these primary questions, but you have the autonomy to ask clarifying follow-up questions if a founder's answer is vague, evasive, or incomplete.

**YOUR OPERATING PROCEDURE:**

1.  **Start the Interview:**
    - When the session begins, greet the founder and state the first primary question.

2.  **Listen to the Founder's Answer:**
    - Carefully analyze the founder's response to your question.

3.  **Assess Answer Quality & Decide Next Step:**
    - **Is the answer complete and direct?**
        - If YES (confidence_in_answer_coverage > 0.85), acknowledge the answer briefly ("Understood.", "Okay, that's clear.") and move to the NEXT primary question.
    - **Is the answer vague, evasive, or missing key details?**
        - If YES (confidence_in_answer_coverage < 0.85), you MUST ask a follow-up question.
        - Your follow-up should be sharp and targeted at the specific gap in their answer.
        - **Follow-up Limit:** You can ask a maximum of {InterviewState().max_followups_per_question} follow-ups for any single primary question. Do not ask a follow-up you have already asked.
        - After the follow-up is answered, re-assess. If still not clear, you can ask another, but once you hit the limit, you must move on. Note the lack of clarity in your assessment.

4.  **Transitioning Between Questions:**
    - Use concise transitions. Examples: "Moving on.", "Next question.", "Let's shift to your go-to-market strategy."

5.  **Ending the Interview:**
    - Once all primary questions have been asked, provide a polite closing statement. Thank the founder for their time and explain the next steps (e.g., "The investment committee will review this conversation.").

**YOUR TONE:**
- **Professional & Authoritative:** You are an expert, not a chatbot.
- **Direct & Concise:** No filler words. Get straight to the point.
- **Inquisitive & Probing:** You are trying to uncover the truth.
- **Never Apologetic:** Don't say "Sorry to interrupt" or "Could you please clarify?". Instead, say "Let me rephrase..." or "That doesn't answer the question. My question was..."

**Example Interaction Flow:**

*   **VentureMind AI (is_primary_question=True):** "The analysis suggests a high CAC. What is your precise, quarter-over-quarter plan to reduce customer acquisition costs without impacting growth rate?"
*   **Founder:** "We're exploring several marketing channels and focusing on organic growth to bring costs down."
*   **VentureMind AI (is_followup_question=True, confidence=0.4):** "That's too high-level. I need the specific, quarter-over-quarter numerical targets for CAC reduction you are committed to."
*   **Founder:** "Okay, in Q3 we're aiming for a 10% reduction, and in Q4 a 15% reduction by shifting budget from paid ads to content marketing."
*   **VentureMind AI (is_primary_question=True, confidence=0.9):** "Understood. Moving on. Your competitor BigTech Corp dominates the enterprise space. How exactly does your core product feature (X) create defensibility...?"

**CURRENT STATE:**
- Today's Date: {datetime.date.today().strftime('%B %d, %Y')}
- You must operate based on the provided `InterviewState`. Do not invent new primary questions.
- Your goal is to get direct answers or expose a lack of direct answers.
"""

# --- The Agent Definition ---

class InterviewAgent(LlmAgent):
    """A stateful agent to conduct interviews, refactored to use subclassing."""
    
    async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:
        """The core logic for the interview flow."""
        session_obj = await ctx.session_service.get_session(ctx.session_id)
        state = InterviewState(**session_obj.state)
        message = ctx.new_message

        # Helper to update state and yield event
        async def update_and_yield(output: InterviewerOutput):
            session_obj.state = state.dict()
            await ctx.session_service.update_session(session_obj)
            yield Event(
                invocation_id=ctx.invocation_id,
                author=self.name,
                branch=ctx.branch,
                content=Content(parts=[Part(text=output.response_text)])
            )

        # --- 1. Initialization Step ---
        if not state.interview_started:
            if not state.questions_list:
                output = InterviewerOutput(
                    response_text="Error: No questions were loaded for this interview session. Please configure the session correctly.",
                    is_followup_question=False,
                    is_primary_question=False,
                    is_closing_statement=True,
                    confidence_in_answer_coverage=0.0
                )
                async for event in update_and_yield(output):
                    yield event
                return

            state.interview_started = True
            state.total_questions = len(state.questions_list)
            state.current_question_index = 0
            
            first_question = f"Hello! I'm VentureMind AI, and I will be your interviewer. We are impressed by your traction. My first question, which is based on our analysis of your documents, is: {state.questions_list[0]}"
            
            state.answers_collected.append({"question": state.questions_list[0], "answers": []})
            state.full_history.append({"role": "bot", "content": first_question})
            state.last_question_asked_by_bot = first_question
            
            output = InterviewerOutput(
                response_text=first_question,
                is_followup_question=False,
                is_primary_question=True,
                is_closing_statement=False,
                confidence_in_answer_coverage=1.0
            )
            async for event in update_and_yield(output):
                yield event
            return

        # --- 2. Process User's Answer ---
        user_answer = message.parts[0].text
        
        state.answers_collected[-1]["answers"].append(user_answer)
        state.full_history.append({"role": "user", "content": user_answer})

        # --- 3. LLM Call to Assess the Answer and Generate Next Response ---
        assessment_prompt = f"""
        You are an expert interview analyst. Your task is to determine if the founder's answer is sufficient and decide the next step.

        **Context:**
        - The question asked was: "{state.last_question_asked_by_bot}"
        - Follow-up questions already asked for this topic: {state.followups_asked}
        - The founder's latest response is: "{user_answer}"
        
        **Analysis & Decision:**
        1.  **Assess Answer Coverage:** How well did the founder's response address the specific question asked? Rate it from 0.0 (not at all) to 1.0 (perfectly).
        2.  **Decision:** Based on the coverage and the number of follow-ups already asked ({state.followup_count_for_current}/{state.max_followups_per_question}), decide the next action.
            - If coverage is high (> 0.85) OR the follow-up limit is reached, move to the next primary question.
            - If coverage is low (< 0.85) AND the follow-up limit is not reached, generate a targeted follow-up question. The follow-up must probe the specific gap in the answer and must not be a repeat of a previous follow-up.

        **Your output MUST be in the format defined by the `InterviewerOutput` schema.**
        """
        
        model_response = await self.canonical_model.generate_content_async(
            assessment_prompt,
            generation_config={"response_mime_type": "application/json"},
        )
        assessed_output = InterviewerOutput.model_validate_json(model_response.text)

        # --- 4. Construct the Response based on the Assessment ---
        final_output: InterviewerOutput
        if not assessed_output.is_followup_question:
            state.current_question_index += 1
            state.followup_count_for_current = 0
            state.followups_asked = []

            if state.current_question_index >= state.total_questions:
                state.interview_complete = True
                response_text = "Thank you for completing the interview. Your comprehensive answers have been recorded and will be analyzed."
                final_output = InterviewerOutput(
                    response_text=response_text,
                    is_followup_question=False,
                    is_primary_question=False,
                    is_closing_statement=True,
                    confidence_in_answer_coverage=assessed_output.confidence_in_answer_coverage
                )
            else:
                next_question = state.questions_list[state.current_question_index]
                response_text = f"Understood. Next question: {next_question}"
                state.answers_collected.append({"question": next_question, "answers": []})
                final_output = InterviewerOutput(
                    response_text=response_text,
                    is_followup_question=False,
                    is_primary_question=True,
                    is_closing_statement=False,
                    confidence_in_answer_coverage=assessed_output.confidence_in_answer_coverage
                )
            state.full_history.append({"role": "bot", "content": response_text})
            state.last_question_asked_by_bot = response_text
        else:
            state.followup_count_for_current += 1
            state.followups_asked.append(assessed_output.response_text)
            state.full_history.append({"role": "bot", "content": assessed_output.response_text})
            state.last_question_asked_by_bot = assessed_output.response_text
            final_output = assessed_output
        
        async for event in update_and_yield(final_output):
            yield event

# --- Instantiate the Agent ---
investor_interview_agent = InterviewAgent(
    name="InvestorInterview_Agent",
    description="Conducts a structured, adaptive interview with startup founders, asking primary and follow-up questions.",
    instruction=investor_interview_instruction,
    model="gemini-1.5-pro-latest",
    output_schema=InterviewerOutput,
    disallow_transfer_to_parent=True,
    disallow_transfer_to_peers=True,
)
